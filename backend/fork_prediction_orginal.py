import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.svm import SVR
import warnings
warnings.filterwarnings('ignore')

# ==================== åŸºç¡€é…ç½® ====================
np.random.seed(42)

# ==================== 1. åŠ è½½CSVæ•°æ® ====================
print("ã€1/8ã€‘åŠ è½½CSVæ•°æ®...")
csv_path = r"C:\Users\22390\Desktop\OpenSODA\backendData\top_300_metrics.csv"

def load_csv_data(file_path,):
    """åŠ è½½CSVæ–‡ä»¶"""
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        print(f"  âœ“ åŠ è½½æ–‡ä»¶: {file_path}")
        print(f"  æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
        return df
    except FileNotFoundError:
        raise ValueError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    except Exception as e:
        raise ValueError(f"âŒ è¯»å–CSVå¤±è´¥: {str(e)}")

try:
    df = load_csv_data(csv_path)
except Exception as e:
    print(e)
    exit()

# ==================== 2. é€‰æ‹©ç›®æ ‡åˆ—å¹¶å¤„ç†ç±»å‹ ====================
print("\nã€2/8ã€‘é€‰æ‹©å¹¶å¤„ç†ç›®æ ‡åˆ—...")
target_column = 'technical_fork'
print(f"âœ“ ä½¿ç”¨ç›®æ ‡åˆ—ï¼š{target_column}")

def convert_to_numeric(col_data):
    """æ™ºèƒ½è½¬æ¢ä¸ºæ•°å€¼å‹"""
    try:
        numeric = pd.to_numeric(col_data, errors='coerce')
        if numeric.isna().mean() < 0.5:
            return numeric
    except:
        pass
    
    try:
        time_formats = ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y/%m/%d', '%Y%m%d']
        for fmt in time_formats:
            try:
                return pd.to_datetime(col_data, format=fmt, errors='raise').astype('int64') // 10**9
            except:
                continue
        return pd.to_datetime(col_data, errors='coerce').astype('int64') // 10**9
    except:
        return pd.to_numeric(col_data, errors='coerce')

# è½¬æ¢ç›®æ ‡åˆ—
df['target_numeric'] = convert_to_numeric(df[target_column])
df_clean = df.dropna(subset=['target_numeric']).reset_index(drop=True)
print(f"âœ“ æœ‰æ•ˆæ•°æ®: {len(df_clean)} æ¡")

# ç›®æ ‡åˆ—ç»Ÿè®¡
print(f"\nç›®æ ‡åˆ—ç»Ÿè®¡ä¿¡æ¯ï¼š")
print(f"  å‡å€¼: {df_clean['target_numeric'].mean():.2f}")
print(f"  æ ‡å‡†å·®: {df_clean['target_numeric'].std():.2f}")
print(f"  æœ€å°å€¼: {df_clean['target_numeric'].min():.2f}")
print(f"  æœ€å¤§å€¼: {df_clean['target_numeric'].max():.2f}")

# ==================== 3. ç‰¹å¾å·¥ç¨‹ ====================
print("\nã€3/8ã€‘ç‰¹å¾å·¥ç¨‹...")

# æ’é™¤å¯èƒ½æ³„æ¼çš„ç‰¹å¾
potential_features = []

# é€‰æ‹©ç‰¹å¾
candidate_features = [
    'bus_factor', 'change_requests', 'change_requests_accepted',
    'change_requests_reviews', 'code_change_lines_add',
    'code_change_lines_remove', 'inactive_contributors',
    'issues_closed', 'issues_new', 'issue_comments',
    'new_contributors'
]

# è½¬æ¢ä¸ºæ•°å€¼ç‰¹å¾
for col in candidate_features:
    if col in df_clean.columns:
        try:
            df_clean[f'feat_{col}'] = pd.to_numeric(df_clean[col], errors='coerce')
            corr = df_clean[f'feat_{col}'].corr(df_clean['target_numeric'])
            if abs(corr) < 0.95:  # æ’é™¤è¿‡é«˜ç›¸å…³æ€§
                median_val = df_clean[f'feat_{col}'].median()
                df_clean[f'feat_{col}'] = df_clean[f'feat_{col}'].fillna(median_val)
                potential_features.append(f'feat_{col}')
                print(f"  {col}: ç›¸å…³æ€§={corr:.3f}")
        except:
            continue

# å¦‚æœç‰¹å¾å¤ªå°‘ï¼Œæ·»åŠ è¡ç”Ÿç‰¹å¾
if len(potential_features) < 3:
    print("  ç”Ÿæˆè¡ç”Ÿç‰¹å¾...")
    if 'feat_code_change_lines_add' in df_clean.columns and 'feat_code_change_lines_remove' in df_clean.columns:
        df_clean['feat_code_change_ratio'] = (df_clean['feat_code_change_lines_add'] + 1) / (df_clean['feat_code_change_lines_remove'] + 1)
        potential_features.append('feat_code_change_ratio')
    
    if 'feat_issues_closed' in df_clean.columns and 'feat_issues_new' in df_clean.columns:
        df_clean['feat_issue_resolution_rate'] = (df_clean['feat_issues_closed'] + 1) / (df_clean['feat_issues_new'] + 1)
        potential_features.append('feat_issue_resolution_rate')

feature_cols = potential_features
print(f"âœ“ ä½¿ç”¨ç‰¹å¾: {len(feature_cols)} ä¸ª")

# ==================== 4. æ•°æ®å‡†å¤‡ ====================
print("\nã€4/8ã€‘æ•°æ®æ‹†åˆ†ä¸æ ‡å‡†åŒ–...")
X = df_clean[feature_cols]
y = df_clean['target_numeric']

# æ‹†åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(
    X, y, df_clean.index, test_size=0.3, random_state=42
)

# æ ‡å‡†åŒ–
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()

print(f"âœ“ æ‹†åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(X_train)} æ¡ï¼Œæµ‹è¯•é›† {len(X_test)} æ¡")

# ==================== 5. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼° ====================
print("\nã€5/8ã€‘æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°...")

# å®šä¹‰æ¨¡å‹
models = {
    'Ridgeå›å½’': Ridge(alpha=1.0, random_state=42),
    'Lassoå›å½’': Lasso(alpha=0.1, random_state=42),
    'æ¢¯åº¦æå‡': GradientBoostingRegressor(
        n_estimators=50, 
        max_depth=3, 
        learning_rate=0.1, 
        random_state=42,
        subsample=0.8
    ),
    'æ”¯æŒå‘é‡æœº': SVR(kernel='linear', C=1.0, epsilon=0.1),
}

# è®­ç»ƒå’Œè¯„ä¼°æ¯ä¸ªæ¨¡å‹
results = {}
for name, model in models.items():
    print(f"\n  è®­ç»ƒ {name}...")
    
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_train_scaled, y_train_scaled)
    
    # é¢„æµ‹
    y_pred_scaled = model.predict(X_test_scaled)
    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
    y_true = y_test.values
    
    # è®­ç»ƒé›†é¢„æµ‹ï¼ˆç”¨äºæ£€æµ‹è¿‡æ‹Ÿåˆï¼‰
    y_train_pred_scaled = model.predict(X_train_scaled)
    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()
    
    # è®¡ç®—æŒ‡æ ‡
    r2_train = r2_score(y_train, y_train_pred)
    r2_test = r2_score(y_true, y_pred)
    rmse_test = np.sqrt(mean_squared_error(y_true, y_pred))
    mae_test = mean_absolute_error(y_true, y_pred)
    
    results[name] = {
        'model': model,
        'r2_train': float(r2_train),  # è½¬æ¢ä¸ºPython float
        'r2_test': float(r2_test),    # è½¬æ¢ä¸ºPython float
        'rmse_test': float(rmse_test), # è½¬æ¢ä¸ºPython float
        'mae_test': float(mae_test),   # è½¬æ¢ä¸ºPython float
        'overfitting_gap': float(r2_train - r2_test),  # è½¬æ¢ä¸ºPython float
        'y_pred': y_pred.tolist(),    # numpyæ•°ç»„è½¬åˆ—è¡¨
        'y_true': y_true.tolist()     # numpyæ•°ç»„è½¬åˆ—è¡¨
    }
    
    print(f"    è®­ç»ƒé›†RÂ²: {r2_train:.4f}")
    print(f"    æµ‹è¯•é›†RÂ²: {r2_test:.4f}")
    print(f"    è¿‡æ‹Ÿåˆå·®è·: {r2_train - r2_test:.4f}")
    print(f"    RMSE: {rmse_test:.2e}")
    print(f"    MAE: {mae_test:.2e}")

# é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºæµ‹è¯•é›†RÂ²ï¼ŒåŒæ—¶è€ƒè™‘è¿‡æ‹Ÿåˆï¼‰
best_model_name = None
best_score = -float('inf')

for name, result in results.items():
    # æƒ©ç½šè¿‡æ‹Ÿåˆä¸¥é‡çš„æ¨¡å‹
    penalty = 0
    if result['overfitting_gap'] > 0.2:
        penalty = 0.3  # ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œå¤§å¹…æƒ©ç½š
    elif result['overfitting_gap'] > 0.1:
        penalty = 0.1  # è½»å¾®è¿‡æ‹Ÿåˆï¼Œè½»å¾®æƒ©ç½š
    
    score = result['r2_test'] - penalty
    
    if score > best_score:
        best_score = score
        best_model_name = name

print(f"\nâœ“ é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼š{best_model_name}")
best_result = results[best_model_name]
best_model = best_result['model']

# ==================== 6. ç‰¹å¾é‡è¦æ€§ ====================
print("\nã€6/8ã€‘ç‰¹å¾é‡è¦æ€§åˆ†æ...")

importance_df = None
if hasattr(best_model, 'coef_'):
    # çº¿æ€§æ¨¡å‹
    importance = best_model.coef_
    if isinstance(importance, np.ndarray):
        importance = importance.tolist()
    
    importance_df = pd.DataFrame({
        "feature_name": feature_cols,
        "importance": importance,
        "abs_importance": [abs(x) for x in importance]
    }).sort_values('abs_importance', ascending=False)
    
elif hasattr(best_model, 'feature_importances_'):
    # æ ‘æ¨¡å‹
    importance = best_model.feature_importances_.tolist()
    importance_df = pd.DataFrame({
        "feature_name": feature_cols,
        "importance": importance,
        "abs_importance": importance
    }).sort_values('abs_importance', ascending=False)

if importance_df is not None:
    print(f"\nğŸ“ˆ ç‰¹å¾é‡è¦æ€§æ’åï¼š")
    for i, row in importance_df.iterrows():
        print(f"  {row['feature_name']:30s}: {row['importance']:.6f}")
else:
    print("âš ï¸  è¯¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")

# ==================== 7. ç”Ÿæˆé¢„æµ‹ç»“æœ ====================
print("\nã€7/8ã€‘ç”Ÿæˆé¢„æµ‹ç»“æœ...")

def format_prediction_value(value, original_series):
    """æ ¼å¼åŒ–é¢„æµ‹å€¼"""
    try:
        if original_series.dropna().apply(lambda x: float(x).is_integer()).all():
            return int(round(value))
        else:
            return round(float(value), 4)
    except:
        return round(float(value), 4)

# è·å–æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ç»“æœ
y_pred = np.array(best_result['y_pred'])
y_true = np.array(best_result['y_true'])

# æ„å»ºç»“æœå­—å…¸ - ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
output_results = {
    "metadata": {
        "target_column": target_column,
        "model_used": best_model_name,
        "feature_columns": feature_cols,
        "total_samples": int(len(df)),
        "valid_samples": int(len(df_clean)),
        "train_samples": int(len(X_train)),
        "test_samples": int(len(X_test)),
        "performance_metrics": {
            "R2_train": float(best_result['r2_train']),
            "R2_test": float(best_result['r2_test']),
            "RMSE_test": float(best_result['rmse_test']),
            "MAE_test": float(best_result['mae_test']),
            "overfitting_gap": float(best_result['overfitting_gap'])
        },
        "model_selection_note": "é€‰æ‹©æ ‡å‡†ï¼šæµ‹è¯•é›†RÂ²æœ€é«˜ï¼ŒåŒæ—¶æƒ©ç½šè¿‡æ‹Ÿåˆä¸¥é‡çš„æ¨¡å‹"
    },
    "model_comparison": {},
    "predictions": []
}

# æ·»åŠ æ¨¡å‹æ¯”è¾ƒä¿¡æ¯
for name, result in results.items():
    output_results["model_comparison"][name] = {
        "R2_train": float(result['r2_train']),
        "R2_test": float(result['r2_test']),
        "overfitting_gap": float(result['overfitting_gap']),
        "selected": bool(name == best_model_name)  # è½¬æ¢ä¸ºPython bool
    }

# å¡«å……é¢„æµ‹ç»“æœ
for i, idx in enumerate(test_idx):
    # è·å–é¡¹ç›®åç§°
    proj_name = ""
    for name_col in ['projectname', 'projectname2']:
        if name_col in df_clean.columns and pd.notna(df_clean.loc[idx, name_col]):
            proj_name = str(df_clean.loc[idx, name_col])
            break
    if not proj_name:
        proj_name = f"é¡¹ç›®_{idx}"
    
    # æ ¼å¼åŒ–å€¼
    true_val = format_prediction_value(y_true[i], df[target_column])
    pred_val = format_prediction_value(y_pred[i], df[target_column])
    
    absolute_error = abs(float(y_true[i]) - float(y_pred[i]))
    relative_error = abs((float(y_true[i]) - float(y_pred[i])) / (abs(float(y_true[i])) + 1e-8)) * 100
    
    output_results["predictions"].append({
        "project_name": proj_name,
        "true_value": float(true_val) if isinstance(true_val, (int, float)) else true_val,
        "predicted_value": float(pred_val) if isinstance(pred_val, (int, float)) else pred_val,
        "absolute_error": round(float(absolute_error), 4),
        "relative_error_percent": round(float(relative_error), 2)
    })

# ==================== 8. ä¿å­˜ç»“æœ ====================
print("\nã€8/8ã€‘ä¿å­˜ç»“æœ...")

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = r'C:\Users\22390\Desktop\OpenSODA\backendData'
os.makedirs(output_dir, exist_ok=True)

# ä¿å­˜é¢„æµ‹ç»“æœ
output_pred = os.path.join(output_dir, 'prediction_results_fixed.json')
with open(output_pred, 'w', encoding='utf-8') as f:
    json.dump(output_results, f, ensure_ascii=False, indent=4)

print(f"âœ“ é¢„æµ‹ç»“æœï¼š{output_pred}")

# ä¿å­˜ç‰¹å¾é‡è¦æ€§
if importance_df is not None:
    # è½¬æ¢importance_dfä¸­çš„å€¼ä¸ºPythonåŸç”Ÿç±»å‹
    importance_records = []
    for _, row in importance_df.iterrows():
        record = {
            "feature_name": str(row['feature_name']),
            "importance": float(row['importance']),
            "abs_importance": float(row['abs_importance'])
        }
        importance_records.append(record)
    
    importance_dict = {
        "model": best_model_name,
        "feature_importance": importance_records
    }
    output_imp = os.path.join(output_dir, 'feature_importance_fixed.json')
    with open(output_imp, 'w', encoding='utf-8') as f:
        json.dump(importance_dict, f, ensure_ascii=False, indent=4)
    print(f"âœ“ ç‰¹å¾é‡è¦æ€§ï¼š{output_imp}")

# ä¿å­˜æ¨¡å‹è¯„ä¼°æ‘˜è¦
summary = {
    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "target_column": target_column,
    "best_model": best_model_name,
    "test_r2": float(best_result['r2_test']),
    "test_rmse": float(best_result['rmse_test']),
    "overfitting_gap": float(best_result['overfitting_gap']),
    "is_overfitted": bool(best_result['overfitting_gap'] > 0.15),  # è½¬æ¢ä¸ºPython bool
    "features_used": int(len(feature_cols))
}
output_summary = os.path.join(output_dir, 'model_summary_fixed.json')
with open(output_summary, 'w', encoding='utf-8') as f:
    json.dump(summary, f, ensure_ascii=False, indent=4)

print(f"âœ“ æ¨¡å‹æ‘˜è¦ï¼š{output_summary}")

# è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
print(f"\nğŸ“‹ æœ€ç»ˆæŠ¥å‘Šï¼š")
print(f"  æœ€ä½³æ¨¡å‹: {best_model_name}")
print(f"  æµ‹è¯•é›†RÂ²: {best_result['r2_test']:.4f}")
print(f"  è®­ç»ƒé›†RÂ²: {best_result['r2_train']:.4f}")
print(f"  è¿‡æ‹Ÿåˆå·®è·: {best_result['overfitting_gap']:.4f}")
print(f"  æ˜¯å¦è¿‡æ‹Ÿåˆ: {'æ˜¯' if best_result['overfitting_gap'] > 0.15 else 'å¦'}")

# è¾“å‡ºæ‰€æœ‰æ¨¡å‹æ¯”è¾ƒ
print(f"\nğŸ“Š æ¨¡å‹æ¯”è¾ƒï¼š")
print(f"  {'æ¨¡å‹åç§°':<15} {'è®­ç»ƒRÂ²':<10} {'æµ‹è¯•RÂ²':<10} {'è¿‡æ‹Ÿåˆå·®è·':<12} {'é€‰æ‹©'}")
print("-" * 60)
for name, result in results.items():
    selected = "âœ“" if name == best_model_name else ""
    print(f"  {name:<15} {result['r2_train']:.4f}     {result['r2_test']:.4f}     {result['overfitting_gap']:.4f}        {selected}")

# è§£é‡Šç»“æœ
print(f"\nğŸ“ ç»“æœè§£é‡Šï¼š")
if best_result['r2_test'] > 0.7:
    print("  âœ… æ¨¡å‹è¡¨ç°ä¼˜ç§€")
elif best_result['r2_test'] > 0.5:
    print("  âš ï¸  æ¨¡å‹è¡¨ç°ä¸€èˆ¬")
elif best_result['r2_test'] > 0.3:
    print("  âš ï¸  æ¨¡å‹è¡¨ç°è¾ƒå·®")
else:
    print("  âŒ æ¨¡å‹è¡¨ç°éå¸¸å·®")

if best_result['overfitting_gap'] > 0.2:
    print("  âŒ ä¸¥é‡è¿‡æ‹Ÿåˆï¼šå»ºè®®å‡å°‘ç‰¹å¾æˆ–å¢åŠ æ­£åˆ™åŒ–")
elif best_result['overfitting_gap'] > 0.1:
    print("  âš ï¸  è½»å¾®è¿‡æ‹Ÿåˆï¼šæ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸€èˆ¬")
else:
    print("  âœ… è¿‡æ‹Ÿåˆé£é™©ä½ï¼šæ¨¡å‹æ³›åŒ–èƒ½åŠ›è‰¯å¥½")

# æ£€æŸ¥æ˜¯å¦ä»ç„¶è¿‡æ‹Ÿåˆ
if best_result['r2_test'] > 0.95:
    print(f"\nâš ï¸  è­¦å‘Šï¼šæ¨¡å‹å¯èƒ½ä»ç„¶è¿‡æ‹Ÿåˆæˆ–å­˜åœ¨æ•°æ®æ³„æ¼ï¼")
    print(f"  å¯èƒ½åŸå› ï¼š")
    print(f"  1. ç‰¹å¾ä¸ç›®æ ‡åˆ—é«˜åº¦ç›¸å…³")
    print(f"  2. æ•°æ®é‡å¤ªå°ï¼ˆä»…{len(df_clean)}æ¡ï¼‰")
    print(f"  3. ç‰¹å¾å·¥ç¨‹éœ€è¦è°ƒæ•´")



